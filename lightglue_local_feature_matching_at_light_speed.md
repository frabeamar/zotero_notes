Handle incorrect correspondences

- filtered by Loweâ€™s ratio test
- mutual check (this we usually do)
- inlier classifiers
- robust fitting geometric models

Are the others worth looking into?

why is the head of lightglue ligher?  
We only have less attention iteration and pruning

BOP challenge ->

there is no mention of *value* in the calculation for self attention, when and how is this used?

NOTE

- you have a range where correspondence are neither inlier or outlier

Read on

- gradient checkpointing
- homography setup in loftr
- DLT algorithm ( is it not least squares? )